{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768abe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "    f.write(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e67bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk the data\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d76e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "# Populate vector database\n",
    "# FAISS does not need a client setup for local use\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = OpenAIEmbeddings()\n",
    ")\n",
    "# Define vectorstore as retriever to enable semantic search\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c300f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Define LLM\n",
    "# gpt-4o-mini is OpenAI's smallest/fastest \"nano-level\" model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use two sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\"What did the president say about Justice Breyer?\", \n",
    "             \"What did the president say about Intel's CEO?\",\n",
    "             \"What did the president say about gun violence?\",\n",
    "            ]\n",
    "ground_truths = [[\"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\"],\n",
    "                [\"The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.\"],\n",
    "                [\"The president asked Congress to pass proven measures to reduce gun violence.\"]]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Inference\n",
    "for query in questions:\n",
    "  answers.append(rag_chain.invoke(query))\n",
    "  # Use .invoke() instead of .get_relevant_documents()\n",
    "  contexts.append([docs.page_content for docs in retriever.invoke(query)])\n",
    "# To dict\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545e5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
